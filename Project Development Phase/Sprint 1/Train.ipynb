{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80541634",
   "metadata": {},
   "source": [
    "# Real-Time Communication System Powered by AI for Specially Abled\n",
    "## CNN Model for Image Prediction\n",
    "### Team ID: PNT2022TMID35896"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d8f784",
   "metadata": {},
   "source": [
    "#### 1. Importing Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1586b0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "import splitfolders\n",
    "import os\n",
    "\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "\n",
    "from tensorflow.keras.preprocessing import image, sequence\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Convolution2D, MaxPooling2D, Flatten,Dropout\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12c6543",
   "metadata": {},
   "source": [
    "#### 2. Load the DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c62c733",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataSet = r'''C:\\Users\\manok\\Documents\\Sem_7\\HX5001-HX6001\\Project Development Phase\\Main Project 1\\Dataset'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8129dca5",
   "metadata": {},
   "source": [
    "#### 3. Image Preprocessing\n",
    "##### 3.1 Import ImageDataGenerator Library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54a55a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, vertical_flip=False)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15889424",
   "metadata": {},
   "source": [
    "##### 3.2. Apply ImageDataGenerator functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7ea26df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15750 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train = train_datagen.flow_from_directory('Dataset/training_set', target_size=(64,64),\n",
    "                                            class_mode='categorical', batch_size=300, color_mode=\"grayscale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c87774e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2250 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "x_test = test_datagen.flow_from_directory('Dataset/test_set', target_size=(64,64),\n",
    "                                            class_mode='categorical', batch_size=300, color_mode=\"grayscale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e7923db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2426abf3",
   "metadata": {},
   "source": [
    "#### 4. Model Building\n",
    "##### 4.1 Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74d007f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfffd969",
   "metadata": {},
   "source": [
    "##### 4.2 Add the Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4b0c6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32,(3,3), input_shape=(64,64,1), activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608714b2",
   "metadata": {},
   "source": [
    "##### 4.3 Add the Pooling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8fab370",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460588c2",
   "metadata": {},
   "source": [
    "##### 4.2 Add the Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a61208c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Convolution2D(16,(3,3), activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbd69c9",
   "metadata": {},
   "source": [
    "##### 4.3 Add the Pooling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cc21d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c010e828",
   "metadata": {},
   "source": [
    "##### 4.4 Add the Flatten Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a06d4cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3cb1e3",
   "metadata": {},
   "source": [
    "##### 4.5 Add the Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e93da40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "# model.add(Dense(100, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "958fa5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(9, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e510988a",
   "metadata": {},
   "source": [
    "##### 4.6 Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abc660ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d1dd3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 16)        4624      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 500)               1568500   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               100200    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,675,453\n",
      "Trainable params: 1,675,453\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b85165",
   "metadata": {},
   "source": [
    "##### 4.7 Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "047f42d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "53/53 [==============================] - 106s 2s/step - loss: 0.4888 - accuracy: 0.8441 - val_loss: 0.1821 - val_accuracy: 0.9604\n",
      "Epoch 2/5\n",
      "53/53 [==============================] - 19s 353ms/step - loss: 0.0731 - accuracy: 0.9783 - val_loss: 0.1465 - val_accuracy: 0.9724\n",
      "Epoch 3/5\n",
      "53/53 [==============================] - 19s 352ms/step - loss: 0.0259 - accuracy: 0.9921 - val_loss: 0.1214 - val_accuracy: 0.9773\n",
      "Epoch 4/5\n",
      "53/53 [==============================] - 72s 1s/step - loss: 0.0193 - accuracy: 0.9943 - val_loss: 0.1150 - val_accuracy: 0.9813\n",
      "Epoch 5/5\n",
      "53/53 [==============================] - 24s 442ms/step - loss: 0.0088 - accuracy: 0.9975 - val_loss: 0.0829 - val_accuracy: 0.9836\n"
     ]
    }
   ],
   "source": [
    "epo=5\n",
    "history = model.fit(x_train, steps_per_epoch=len(x_train), epochs=epo, validation_data=x_test, validation_steps=len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04e07aa",
   "metadata": {},
   "source": [
    "##### 4.8 Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "233c4faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('aslpng1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b929a81",
   "metadata": {},
   "source": [
    "#### 5.Test the Model\n",
    "##### 5.1 Load the Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02bda917",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('aslpng1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49d86b7",
   "metadata": {},
   "source": [
    "##### 5.2 Pre-Process it and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7d13ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(frame):\n",
    "    img=resize(frame,(64,64,1))\n",
    "    img=np.expand_dims(img,axis=0)\n",
    "    if(np.max(img)>1):\n",
    "        img=img/255.0\n",
    "    prediction=model.predict(img)\n",
    "    print(prediction)\n",
    "    prediction=np.argmax(model.predict(img),axis=1) #model.predict_classes(img)\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b3048ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 753ms/step\n",
      "[[3.7539005e-05 1.7786239e-06 2.3852207e-09 5.9640307e-08 9.9912983e-01\n",
      "  3.5570082e-08 2.2522347e-08 7.7758919e-08 8.3063956e-04]]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[4]\n"
     ]
    }
   ],
   "source": [
    "frame=cv2.imread(r'''C:\\Users\\manok\\Documents\\Sem_7\\HX5001-HX6001\\Project Development Phase\\Main Project 1\\Dataset\\training_set\\E\\16.png''')\n",
    "data=detect(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67dec033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[2.7168423e-09 1.4303453e-10 4.5230378e-10 3.3195090e-04 2.5011258e-07\n",
      "  6.0034699e-06 2.0270646e-10 2.0018900e-10 9.9966180e-01]]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[8]\n"
     ]
    }
   ],
   "source": [
    "frame=cv2.imread(r'''C:\\Users\\manok\\Documents\\Sem_7\\HX5001-HX6001\\Project Development Phase\\Main Project 1\\Dataset\\training_set\\I\\30.png''')\n",
    "data=detect(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1cc8932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "[[3.91379373e-08 3.15541904e-09 1.61084827e-05 5.61944020e-08\n",
      "  1.62014757e-07 3.47337163e-07 9.99871969e-01 1.11333764e-04\n",
      "  1.41897938e-10]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "[6]\n"
     ]
    }
   ],
   "source": [
    "frame=cv2.imread(r'''C:\\Users\\manok\\Documents\\Sem_7\\HX5001-HX6001\\Project Development Phase\\Main Project 1\\Dataset\\training_set\\G\\1000.png''')\n",
    "data=detect(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef4ae7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 3)\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "[[3.91379373e-08 3.15541904e-09 1.61084827e-05 5.61944020e-08\n",
      "  1.62014757e-07 3.47337163e-07 9.99871969e-01 1.11333764e-04\n",
      "  1.41897938e-10]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "[6]\n"
     ]
    }
   ],
   "source": [
    "frame=cv2.imread(r'''C:\\Users\\manok\\Documents\\Sem_7\\HX5001-HX6001\\Project Development Phase\\Main Project 1\\Dataset\\training_set\\G\\1000.png''')\n",
    "print(frame.shape)\n",
    "data=detect(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88984ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
